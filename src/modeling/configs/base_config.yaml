# base_config.yaml
# =================
#
# Fichier unique de config pour tout le pipeline d'entraînement.
# Modifie ces valeurs pour tes expériences, puis relance simplement train.py.


# --------------------------------------------------------------------------
# Données
# --------------------------------------------------------------------------
# experiment_name: "exp1"                 # Nom de l'expérience (créera un sous-dossier)

dataset_filepath: "data/npz_datasets/soapgpu_ns120_5000-5010_dx4_sm3_rassine_noise_p53_k0p1_phi0.npz"  # Chemin complet du NPZ standardisé
output_root_dir: "experiments"                                # Répertoire racine pour tous les outputs (local)

data_dtype: float32       # Type numpy/torch du tableau des spectres (float16/float32/float64)

checkpoint_every: 100       # Fréquence de sauvegarde des checkpoints (en epochs)

# --------------------------------------------------------------------------
# DataLoader
# --------------------------------------------------------------------------
batch_size: 32            # Nombre d'échantillons par batch
shuffle: false            # True pour mélanger à chaque epoch

# --------------------------------------------------------------------------
# Augmentation
# --------------------------------------------------------------------------
M_aug: 1                  # Combien de versions augmentées par spectre
vmin: -3                  # Vitesse min (m/s) pour décalage Doppler
vmax: +3                  # Vitesse max (m/s)
interpolate: "linear"     # Méthode d'interpolation
extrapolate: "linear"     # Méthode d'extrapolation hors bornes
out_dtype: float32        # Type de sortie des spectres augmentés (float16 économise ~50% mémoire GPU)

# --------------------------------------------------------------------------
# Modèle
# --------------------------------------------------------------------------
latent_dim: 3             # Dimension de l'espace latent (anciennement "S")
sigma_v: 0.3              # Écart-type pour le bruit Doppler
sigma_c: 0.0001              # Écart-type pour le bruit spectral
sigma_y: 1              # Écart-type pour le bruit de flux
k_reg_init: 0.               # Coefficient de régularisation pour la perte
cycle_length: 1000        # Nombre d'itérations pour le cycle de régularisation
model_dtype: float32      # Type de données pour les poids du modèle (float16/float32/float64)

# --------------------------------------------------------------------------
# Mixed Precision Settings
# --------------------------------------------------------------------------
use_mixed_precision: true        # Activer la mixed precision
mixed_precision_dtype: float16   # Type de données pour les forward passes (float16)
autocast_enabled: true          # Utiliser autocast pour le forward pass
grad_scaler_enabled: true       # Utiliser GradScaler pour éviter les underflows
grad_scaler_init_scale: 65536.0 # Échelle initiale pour le gradient scaler
grad_scaler_growth_factor: 2.0  # Facteur de croissance du scaler
grad_scaler_backoff_factor: 0.5 # Facteur de réduction du scaler
grad_scaler_growth_interval: 2000 # Intervalle de croissance du scaler


# --------------------------------------------------------------------------
# Logging et plots
# --------------------------------------------------------------------------
save_losses_csv: true     # Sauver les losses dans un fichier CSV
csv_save_every: 100       # Fréquence de sauvegarde CSV (en epochs)
plot_every: 50             # Plot des losses tous les X epochs (0 = désactivé)
plot_rv_every: 50         # Plot des prédictions RV tous les X epochs (0 = désactivé)

# --------------------------------------------------------------------------
# Phases d'entraînement
# --------------------------------------------------------------------------
phases:
  - name: rvonly
    n_epochs: 200
    optimizer: "torch.optim.Adam"
    optimizer_kwargs:
      lr: 0.0001
      weight_decay: 0.0
    b_obs_trainable: false
    b_rest_trainable: false
    # early_stopping:
    #   patience: 20
    #   min_delta: 1e-6
    #   metric: "total"
    #   mode: "min"
    #   restore_best_weights: true
    
  - name: joint
    n_epochs: 200
    optimizer: "torch.optim.Adam"
    optimizer_kwargs:
      lr: 0.0001
      weight_decay: 0.0
    scheduler: "torch.optim.lr_scheduler.StepLR"
    scheduler_kwargs:
      step_size: 50
      gamma: 0.7
    b_obs_trainable: false
    b_rest_trainable: true
    plot_activity_every: 20
    # early_stopping:
    #   patience: 15
    #   min_delta: 1e-7
    #   metric: "rv"
    #   mode: "min"
    #   restore_best_weights: true
