# base_config.yaml
# =================
#
# Fichier unique de config pour tout le pipeline d'entraînement.
# Modifie ces valeurs pour tes expériences, puis relance simplement train.py.


# --------------------------------------------------------------------------
# Données
# --------------------------------------------------------------------------
dataset_filepath: "data/npz_datasets/dataset_1000specs_5000_5300_Kp1e-1_P100.npz"  # Chemin complet du NPZ standardisé
data_dtype: float32       # Type numpy/torch du tableau des spectres (float16/float32/float64)

checkpoint_every: 100       # Fréquence de sauvegarde des checkpoints (en epochs)

# --------------------------------------------------------------------------
# DataLoader
# --------------------------------------------------------------------------
batch_size: 32            # Nombre d'échantillons par batch
shuffle: false            # True pour mélanger à chaque epoch

# --------------------------------------------------------------------------
# Augmentation
# --------------------------------------------------------------------------
M_aug: 1                  # Combien de versions augmentées par spectre
vmin: -3                  # Vitesse min (m/s) pour décalage Doppler
vmax: +3                  # Vitesse max (m/s)
interpolate: "linear"     # Méthode d'interpolation
extrapolate: "linear"     # Méthode d'extrapolation hors bornes
out_dtype: float32        # Type de sortie des spectres augmentés (float16 économise ~50% mémoire GPU)

# --------------------------------------------------------------------------
# Modèle
# --------------------------------------------------------------------------
latent_dim: 3             # Dimension de l'espace latent (anciennement "S")
sigma_v: 0.3              # Écart-type pour le bruit Doppler
sigma_c: 0.0001              # Écart-type pour le bruit spectral
sigma_y: 1              # Écart-type pour le bruit de flux
k_reg_init: 0.               # Coefficient de régularisation pour la perte
cycle_length: 1000        # Nombre d'itérations pour le cycle de régularisation
b_obs_trainable: false    # Spectre observé fixe ou ajustable ?
b_rest_trainable: true    # Spectre template (repos) entraînable ?
model_dtype: float32      # Type de données pour les poids du modèle (float16/float32/float64)

# --------------------------------------------------------------------------
# Mixed Precision Settings
# --------------------------------------------------------------------------
use_mixed_precision: true        # Activer la mixed precision
mixed_precision_dtype: float16   # Type de données pour les forward passes (float16)
autocast_enabled: true          # Utiliser autocast pour le forward pass
grad_scaler_enabled: true       # Utiliser GradScaler pour éviter les underflows
grad_scaler_init_scale: 65536.0 # Échelle initiale pour le gradient scaler
grad_scaler_growth_factor: 2.0  # Facteur de croissance du scaler
grad_scaler_backoff_factor: 0.5 # Facteur de réduction du scaler
grad_scaler_growth_interval: 2000 # Intervalle de croissance du scaler

# --------------------------------------------------------------------------
# Output Organization
# --------------------------------------------------------------------------
output_root_dir: "experiments"                                # Répertoire racine pour tous les outputs (local)
experiment_name: "aestra_local_experiment"                 # Nom de l'expérience (créera un sous-dossier)

# --------------------------------------------------------------------------
# Logging des losses
# --------------------------------------------------------------------------
save_losses_csv: true     # Sauver les losses dans un fichier CSV
csv_save_every: 100       # Fréquence de sauvegarde CSV (en epochs)
plot_every: 0             # Plot des losses tous les X epochs (0 = désactivé)
plot_rv_every: 50          # Plot des prédictions RV (dataset complet) tous les X epochs (0 = désactivé)
plot_rv_chunk_size: 256   # Taille des chunks pour le calcul des RV sur tout le dataset

# --------------------------------------------------------------------------
# Phases d'entraînement
# --------------------------------------------------------------------------
phases:
  - name: rvonly
    n_epochs: 200
    optimizer: "torch.optim.Adam"
    optimizer_kwargs:
      lr: 0.0001
      weight_decay: 0.0
    b_obs_trainable: false
    b_rest_trainable: false
    # plot_rv_every: 10           # (optionnel) override par-phase
    # plot_rv_chunk_size: 512     # (optionnel) override par-phase

  - name: joint
    n_epochs: 100
    optimizer: "torch.optim.Adam"
    optimizer_kwargs:
      lr: 0.0001
      weight_decay: 0.0
    b_obs_trainable: false
    b_rest_trainable: true
    # plot_rv_every: 10           # (optionnel) override par-phase
    # plot_rv_chunk_size: 512     # (optionnel) override par-phase