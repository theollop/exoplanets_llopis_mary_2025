# base_config.yaml
# =================
#
# Fichier unique de config pour tout le pipeline d'entraînement.
# Modifie ces valeurs pour tes expériences, puis relance simplement train.py.


# --------------------------------------------------------------------------
# Données
# --------------------------------------------------------------------------
# experiment_name: ""                 # Nom de l'expérience (créera un sous-dossier)
# /content/drive/MyDrive/aestra_training/data/npz_datasets/

dataset_filepath: "/content/drive/MyDrive/aestra_training/data/npz_datasets/soapgpu_ns3292_5000-5050_dx2_sm3_nonoise__baseline.npz"  # Chemin complet du NPZ standardisé
output_root_dir: "/content/drive/MyDrive/aestra_training/experiments"                                # Répertoire racine pour tous les outputs (local)

data_dtype: float32       # Type numpy/torch du tableau des spectres (float16/float32/float64)

checkpoint_every: 100       # Fréquence de sauvegarde des checkpoints (en epochs)


# --------------------------------------------------------------------------
# DataLoader avancé (contrôle CPU/GPU, workers, transferts)
# --------------------------------------------------------------------------
batch_size: 32            # Nombre d'échantillons par batch
shuffle: true           # True pour mélanger à chaque epoch
num_workers: 2           # Nombre de workers pour le DataLoader (0 = main process)
pin_memory: true         # Active le pinning mémoire (recommandé si GPU)
prefetch_factor: 2       # Nombre de batches préchargés par worker (si num_workers>0)
persistent_workers: true # Garde les workers vivants entre les epochs (si num_workers>0)
dataset_cuda: false      # Si true, charge tout le dataset sur le GPU (déconseillé pour gros jeux de données)
move_batches_to_device: true  # Transfert chaque batch sur le device du modèle (recommandé)
non_blocking_transfer: true   # Utilise le transfert non bloquant CPU→GPU

# --------------------------------------------------------------------------
# Augmentation
# --------------------------------------------------------------------------
M_aug: 1                  # Combien de versions augmentées par spectre
vmin: -3                  # Vitesse min (m/s) pour décalage Doppler
vmax: +3                  # Vitesse max (m/s)
interpolate: "linear"     # Méthode d'interpolation
extrapolate: "linear"     # Méthode d'extrapolation hors bornes
out_dtype: float32        # Type de sortie des spectres augmentés (float16 économise ~50% mémoire GPU)

# --------------------------------------------------------------------------
# Modèle
# --------------------------------------------------------------------------
latent_dim: 3             # Dimension de l'espace latent (anciennement "S")

# Loss RV
sigma_v: 0.1              # Écart-type pour le bruit Doppler

# Loss reg
sigma_y: 0.15              # Écart-type pour le bruit de flux
k_reg_init: 0.05              # Coefficient de régularisation pour la perte
cycle_length: 200        # Nombre d'itérations pour le cycle de régularisation

# Loss consistency
get_aug_data: False         # Si True, calcule les données augmentées dans le forward pass et permet de calculer la loss de consistency
sigma_s: 1              # Poids dans la loss de consistency

model_dtype: float32      # Type de données pour les poids du modèle (float16/float32/float64)

# --------------------------------------------------------------------------
# Mixed Precision Settings
# --------------------------------------------------------------------------
use_mixed_precision: true        # Activer la mixed precision
mixed_precision_dtype: float16   # Type de données pour les forward passes (float16)
autocast_enabled: true          # Utiliser autocast pour le forward pass
grad_scaler_enabled: true       # Utiliser GradScaler pour éviter les underflows
grad_scaler_init_scale: 65536.0 # Échelle initiale pour le gradient scaler
grad_scaler_growth_factor: 2.0  # Facteur de croissance du scaler
grad_scaler_backoff_factor: 0.5 # Facteur de réduction du scaler
grad_scaler_growth_interval: 2000 # Intervalle de croissance du scaler


# --------------------------------------------------------------------------
# Logging et plots
# --------------------------------------------------------------------------
save_losses_csv: true     # Sauver les losses dans un fichier CSV
csv_save_every: 100       # Fréquence de sauvegarde CSV (en epochs)
plot_every: 50             # Plot des losses tous les X epochs (0 = désactivé)
plot_rv_every: 50         # Plot des prédictions RV tous les X epochs (0 = désactivé)

# --------------------------------------------------------------------------
# Phases d'entraînement
# --------------------------------------------------------------------------
phases:
  - name: rvonly
    n_epochs: 100

    trainable_params:
      b_obs: false
      b_rest: false
      rvestimator: true
      spender: false

    optimizer: "torch.optim.Adam"
    optimizer_kwargs:
      lr: 0.0001
      weight_decay: 0.0

    # early_stopping:
    #   patience: 20
    #   min_delta: 1e-6
    #   metric: "total" 
    #   mode: "min"
    #   restore_best_weights: true

  - name: joint1
    n_epochs: 20
    
    trainable_params:
      b_obs: false
      b_rest: false
      rvestimator: true
      spender: true

    optimizer: "torch.optim.Adam"
    optimizer_kwargs:
      lr: 0.0001
      weight_decay: 0.0
    
    plot_activity_every: 2
    
  - name: joint2
    n_epochs: 200
    
    trainable_params:
      b_obs: false
      b_rest: true
      rvestimator: true
      spender: true
    
    optimizer: "torch.optim.Adam"
    optimizer_kwargs:
      lr: 0.0001
      weight_decay: 0.0
    
    scheduler: "torch.optim.lr_scheduler.StepLR"
    scheduler_kwargs:
      step_size: 50
      gamma: 0.7
    
    plot_activity_every: 20
    # early_stopping:
    #   patience: 15
    #   min_delta: 1e-7
    #   metric: "rv"
    #   mode: "min"
    #   restore_best_weights: true
